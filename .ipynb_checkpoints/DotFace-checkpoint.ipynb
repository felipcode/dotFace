{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09b8311b-69d9-4967-8515-f6d034c811cd",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "439a9b86-75e5-4eed-8142-d3bd28c39367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "device = 'cuda'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af151541-5757-4b4f-ba18-5d11374a9139",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b540947-fb3d-4321-9f23-dfee40af0bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset_DirectoryORG(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = os.listdir(root_dir)\n",
    "        self.class_to_idx = {cls_name: i for i, in enumerate(self.classes)}\n",
    "        self.img_paths = self.get_image_paths()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, target = self.img_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, target\n",
    "\n",
    "    def get_image_paths(self):\n",
    "        img_paths = []\n",
    "        for cls_name in self.classes:\n",
    "            class_dir = os.path.join(self.root_dir, cls_name)\n",
    "            if not os.path.isdir(class_dir):\n",
    "                continue\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                img_paths.append((img_path, self.class_to_idx[cls_name]))\n",
    "        return img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0502302-630d-481b-b467-d952efdea9c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load pretrained InceptionResnetV1 model\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "detector = MTCNN(keep_all=True, device=device, margin=10)\n",
    "\n",
    "def get_face_embedding(image):\n",
    "    # Preprocess image\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    pil_image = Image.fromarray(image)\n",
    "\n",
    "    # Detect face and get bounding box\n",
    "    boxes, _ = detector.detect(pil_image)\n",
    "\n",
    "    # If no face is detected or bounding box is empty, return None\n",
    "    if boxes is None or len(boxes) == 0:\n",
    "        return None\n",
    "\n",
    "    # Extract face from image\n",
    "    x, y, w, h = boxes[0].astype(int)\n",
    "    face_image = image[y:h, x:w]\n",
    "\n",
    "    # Check if face image has valid size\n",
    "    if face_image.size == 0:\n",
    "        return None\n",
    "\n",
    "    # Resize face image to match model input size\n",
    "    face_image = cv2.resize(face_image, (160, 160))\n",
    "\n",
    "    # Convert face image to tensor and normalize\n",
    "    face_tensor = torch.tensor(face_image).permute(2, 0, 1).float() / 255.0\n",
    "\n",
    "    # Add batch dimension\n",
    "    face_tensor = face_tensor.unsqueeze(0)\n",
    "\n",
    "    # Get face embedding using InceptionResnetV1 model\n",
    "    embedding = resnet(face_tensor).detach().numpy()\n",
    "\n",
    "    return embedding\n",
    "\n",
    "# Define known faces and their embeddings (you need to populate this with your own known faces)\n",
    "known_faces = {\n",
    "    \"person1\": get_face_embedding(cv2.imread(\"./DATA_TRAIN/Ari/2.webp\")),\n",
    "    \"person2\": get_face_embedding(cv2.imread(\"./DATA_TRAIN/SummerWalker/1.webp\")),\n",
    "    # Add more known faces as needed\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e320541d-a624-4a47-bd49-ab8884ac803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to capture frame\")\n",
    "        break\n",
    "\n",
    "    # Get face embeddings of detected faces\n",
    "    detected_faces = detector.detect_faces(frame)\n",
    "    if detected_faces is not None:\n",
    "        for box, _ in detected_faces:\n",
    "            x, y, w, h = box.astype(int)\n",
    "            detected_face = frame[y:h, x:w]\n",
    "            detected_embedding = get_face_embedding(detected_face)\n",
    "\n",
    "            # Compare detected face embeddings with known faces\n",
    "            for name, known_embedding in known_faces.items():\n",
    "                if known_embedding is not None:\n",
    "                    # Compute L2 distance between embeddings\n",
    "                    distance = np.linalg.norm(detected_embedding - known_embedding)\n",
    "\n",
    "                    # If distance is below a threshold, it's a match\n",
    "                    if distance < threshold:\n",
    "                        cv2.rectangle(frame, (x, y), (w, h), (0, 255, 0), 2)\n",
    "                        cv2.putText(frame, name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Webcam', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29eba0f-2406-4572-87d8-069e674947ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
